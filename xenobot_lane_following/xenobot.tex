\documentclass{article}
\usepackage[utf8]{inputenc}
\usepackage{amsmath}
\usepackage[linesnumbered,ruled]{algorithm2e}
\usepackage{mathtools}
\usepackage{commath}
\usepackage{bm}
\usepackage{hyperref}
\usepackage{tikz}
\usepackage{placeins}
\usepackage{listings}
\usetikzlibrary{shapes.geometric, arrows}

\title{Xenobot technical report \\  Lane following}
\author{\textbf{Shengwen Cheng , Po-Sheng Chen}}
\date{January 2017}

\begin{document}

\maketitle

\tikzstyle{blocks} = [rectangle, rounded corners, minimum width=2cm, minimum height=1cm,text centered, draw=black, fill=orange!30]
\tikzstyle{arrow} = [thick,->,>=stealth]

\section{Introduction}
Xenobot is a computer vision based self-driving system inspired by MIT duckietown project. We re-implement our own system for real-time robotics research and may add more new features in the future.
\\
\\
The algorithm we're using is a modified version of MIT duckietown, so you can find many similarities between two projects. This report is focus on how our lane following algorithm works.
\\
\\
\\
\\

\begin{figure}[ht]
  \label{fig:xenobot}
  \centering
  \includegraphics[scale=0.3]{graphs/xenobot.PNG}
  \caption{Xenobot}
\end{figure}

\clearpage

\section{Camera calibrations}

Camera calibration is a early stage mission before doing the computer vision, they're two set of parameters need to be found, intrinsic parameters and extrinsic parameter, by estimate them we can know the relation between 2D image plane and 3D world. 

\subsection{Intrinsic parameters}

The intrinsic matrix describes the projection from 3D world into 2D image plane. The ideal linear model is consist of focal length, pixel size and principal point. The nonlinear effect like lens distortion are also important however can not described in the linear camera model and usually solved by numerical methods.

\subsection{Extrinsic parameters}

The extrinsic matrix describes the translation and rotation of camera with respect to the world frame, which mean the angle and position of camera taking pictures in 3D world.

\clearpage

\section{Lane pose estimation}

\subsection{Lane pose and system conventions}
\begin{figure}[ht]
  \label{fig:lane_coordination}
  \centering
  \includegraphics[scale=0.6]{graphs/coordinate_system.PNG}
  \caption{Lane coordination}
\end{figure}
\FloatBarrier

\begin{figure}[ht]
  \label{fig:lane_2d_view}
  \centering
  \includegraphics[scale=0.6]{graphs/lane_parameter_2d_view.PNG}
  \caption{2D view of lane}
\end{figure}
\FloatBarrier

\begin{figure}[ht]
  \label{fig:lane_pose}
  \centering
  \includegraphics[scale=0.7]{graphs/lane_pose.PNG}
  \caption{Lane pose}
\end{figure}
\FloatBarrier

\subsection{Segements detection}

The first step for lane pose estimation is to extract the segments from the image, the process to do this is to threshold the specific color we want, and apply canny edge detector and Hough transform so we can find out the location of those segments

\begin{figure} [ht]
\begin{center}
\begin{tikzpicture}[node distance=2cm]
\node (raw) [blocks, yshift=0cm] {Raw image} ;
\node (rectify) [blocks, yshift=-1.5cm] {Distortion and rectification};
\node (canny) [blocks, xshift=-2cm, yshift=-3cm] {Canny edge detection};
\node (diliation_canny) [blocks, xshift=-2cm, yshift=-4.5cm] {Diliation};
\node (threshold) [blocks, xshift=2cm, yshift=-3cm] {HSV color thresholding};
\node (diliation_threshold) [blocks, xshift=2cm, yshift=-4.5cm] {Diliation};
\node (and) [blocks, yshift=-6cm] {Bitwise And};
\node (hough) [blocks, yshift=-7.5cm] {Hough transform};
\node (segments) [blocks, yshift=-9cm] {Segments};

\draw [arrow] (raw) -- (rectify);
\draw [arrow] (rectify) -- (canny);
\draw [arrow] (canny) -- (diliation_canny);
\draw [arrow] (rectify) -- (threshold);
\draw [arrow] (threshold) -- (diliation_threshold);
\draw [arrow] (diliation_canny) -- (and);
\draw [arrow] (diliation_threshold) -- (and);
\draw [arrow] (and) -- (hough);
\draw [arrow] (hough) -- (segments);
\end{tikzpicture}
\end{center}
\caption{Work flow of lane detector}
\end{figure}
\FloatBarrier


\subsection{Frame transformation}

The camera on the car is mounted in a distance from the origin. In order to know the real lateral displacement of the car, a transformation is need for converting camera frame into car frame.

\[
\begin{pmatrix} x_{car} \\ y_{car} \end{pmatrix} = 
\begin{pmatrix} x_{camera} - r \cdot \sin\phi \\ y_{camera} - r \cdot \cos\phi \end{pmatrix}
\]

\begin{figure}[ht]
  \label{fig:frame_transformation}
  \centering
  \includegraphics[scale=0.7]{graphs/frame_transformation.PNG}
  \caption{Frame transformation}
\end{figure}
\FloatBarrier

\subsection{Segment side recognition}

Canny edge detection and Hough transform find the lane segments for us. However, we still don't know the segments is on which side of the lane mark.
\\
\\
To determine the side, we can read multiple pixels in both positive and negative direction of the segment normal vector on color thresholded image. 

\begin{figure}[ht]
  \label{fig:lane_segment}
  \centering
  \includegraphics[scale=0.4]{graphs/segment.PNG}
  \caption{Lane segments}
\end{figure}
\FloatBarrier

\begin{figure} [ht]
\begin{algorithm}[H]
	\KwData{segment, accumulator threshold, color binarization image}
	\KwResult{side (left or right)}
	$\vec{P_1} = (x_1, y_1)$
	\\
	$\vec{P_2} = (x_2, y_2)$
	\\
	$\vec{P} = (\vec{P_1} + \vec{P_2}) / 2$
	\\
	$\vec{t} = \frac{\vec{P_2} - \vec{P_1}}
					{\norm{\vec{P_2} - \vec{P_1}}}$
	\\
	$\vec{n} = (-y_t, x_t)$
	\\
	\For {$i < pixel \ count$} {
		$x \gets \lceil x_p + x_n \cdot i \rceil$
		\\
		$y \gets \lceil y_p + y_n \cdot i \rceil$
		\\		
		\uIf{$I(x,y) = I_{max}$}
			{
				$left \mathrel{+}= 1$ 
			}
			
		$x \gets \lfloor x_p - x_n \cdot i \rfloor$
		\\
		$y \gets \lfloor y_p - y_n \cdot i \rfloor$
		\\		
		\uIf{$I(x,y) = I_{max}$}
			{
				$right \mathrel{+}= 1$ 
			}
	}
	
	\uIf {$left > threshold \ \& \  right < threshold$}
		{
			\Return is left
		}
	\uElseIf {$right > threshold \ \& \ left < threshold$}
		{
			\Return is right
		}
	\uElse
		{
			\Return unknown side
		} 
	\caption{Segment side recognition}
\end{algorithm}
\end{figure}
\FloatBarrier

\subsection{Segment pose estimation}

\begin{figure}[ht]
  \label{fig:lane_geometry}
  \centering
  \includegraphics[scale=1]{graphs/lane_geometry.PNG}
  \caption{Lane geometry}
\end{figure}
\FloatBarrier

\begin{figure} [ht]
\begin{algorithm}[H]
	\KwData{segment}
	\KwResult{pose $d_{i}$ and $\phi_{i}$}
	$\vec{P_1} = (x_1, y_1)$

	$\vec{P_2} = (x_2, y_2)$

	$\vec{t} = \frac{\vec{P_2} - \vec{P_1}}
					{\norm{\vec{P_2} - \vec{P_1}}}$

	$\vec{n} = (-y_t, x_t)$

	$\phi_{i} = \arctan(\frac{y_t}{x_t}) - \pi / 2$

	\uIf {segment color = white}
		{
			\eIf{edge side = right}
			{
				$\vec{k} = (\frac{w}{2} + l_w) \cdot \vec{n}$
			}
			{
				$\vec{k} = (\frac{w}{2}) \cdot \vec{n}$
			}
		}
	\uElseIf {segment color = yellow}
		{
			\eIf{edge side = left}
			{
				$\vec{k} = (-\frac{w}{2} - l_y) \cdot \vec{n}$
			}
			{
				$\vec{k} = (-\frac{w}{2}) \cdot \vec{n}$
			}
		}
	$\vec{j} = (r \cdot \sin\phi, r \cdot \cos\phi)$

	$\vec{P_1^\prime} = \vec{P_1} + \vec{k} - \vec{j}$

	$\vec{P_2^\prime} = \vec{P_2} + \vec{k} - \vec{j}$

	$d_1 = \vec{P_1} \cdot \vec{n}$

	$d_2 = \vec{P_2} \cdot \vec{n}$

	$d_{i} = (d_1 + d_2) / 2$
	\caption{Generate vote}
\end{algorithm}
\caption{Vote generation}
\end{figure}
\FloatBarrier

\subsection{Histogram filter}

\begin{figure}[ht]
  \label{fig:histogram_filter}
  \centering
  \includegraphics[scale=0.9]{graphs/histogram_filter.PNG}
  \caption{Histogram filter}
\end{figure}
\FloatBarrier

\begin{figure} [ht]
\begin{algorithm}[H]
	\KwData{segment}
	\KwResult{filtered pose $d$ and $\phi$}
	\For {$\bm{all}$ segments} {
			$(\phi_i, d_i) \gets generate\_vote(segment)$
			
			$I \gets round(\frac{\phi_i - \phi_{min}}{\Delta\phi})$

			$J \gets round(\frac{d_i - d_{min}}{\Delta d})$
			
			$histogram(I, J) \mathrel{+}= 1$
	}
	
	$(I_{highest}, J_{highest}) \gets find \_ highest \_ vote()$	
	
	$\phi_{histogram} \gets I_{highest} \cdot \Delta \phi + \phi_{min}$
	
	$d_{histogram} \gets J_{highest} \cdot \Delta d + d_{min}$

	$\phi_{mean} \gets 0 \ , \  d_{mean} \gets 0$
	
	$N_{\phi} \gets 0 \ , \ N_{d} \gets 0$
	
	\For {$\bm{all} \ (\phi_{i}, d_{i})$}
	{
		\uIf {$\phi_{i} \in [\phi_{histogram} - \frac{\Delta \phi}{2}, 
			  \phi_{histogram} + \frac{\Delta \phi}{2}]$}
		{
			$\phi_{mean} \mathrel{+}= \phi_{i}$
			
			$N_{\phi} \mathrel{+}= 1$
		}
		
		\uIf {$d_{i} \in [d_{histogram} - \frac{\Delta d}{2}, 
			  d_{histogram} + \frac{\Delta d}{2}]$}
		{
			$d_{mean} \mathrel{+}= d_{i}$
			
			$N_{d} \mathrel{+}= 1$
		}
	}
	
	$\phi_{mean} \gets \frac{\phi_{mean}}{N_{\phi}}$
	
	$d_{mean} \gets \frac{d_{mean}}{N_{d}}$	
	\caption{Histogram filter}
\end{algorithm}
\caption{Histogram filter}
\end{figure}
\FloatBarrier

\clearpage

\section{Control system}

\subsection{Differential wheels}

\subsection{PID Controller}

Xenobot use the well known algorithm \textbf{"PID controller"} to fix the orientation and lateral displacement.
\\
\\
The equation of PID controller in continuous time is given as:

\[e(t) = setpoint(t) - x(t)\]

\[u(t) = K_p e(t) + K_i \int_{0}^{t} e(\tau) d\tau + K_d  \frac{de(t)}{dt}\]

\noindent and for discreted time:

\[e[t] = setpoint[t] - x[t]\]

\[u[t] = K_p e[t] + K_i \sum_0^t e[t] \Delta t + K_d \frac{e[t] - e[t-1]}{\Delta t}\]

\subsection{Pose control}

The pose controller of Xenobot is a cascaded PID controller.
\\
\\
The phi controller is a low level contoller for lane orientation stablizing, and d controller fix the lateral displacement by changing the setpoint of phi controller to turn left or right.

\begin{figure}[ht]
  \label{fig:control_diagram}
  \centering
  \includegraphics[scale=0.6]{graphs/control_diagram.PNG}
  \caption{Control diagram}
\end{figure}
\FloatBarrier

\noindent The wheel control signal (PWM) is simply the throttle value plus the correction value:

\begin{lstlisting}
pwm_left = THROTTLE__BASE - pwm_correction
pwm_right = THROTTLE__BASE + pwm_correction
\end{lstlisting}

\clearpage

\section{References}

[1] Lane Filter by Liam Paull, MIT CSAIL

\end{document}